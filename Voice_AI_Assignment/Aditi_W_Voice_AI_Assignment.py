# -*- coding: utf-8 -*-
"""Final_Done_Colab_Akaike_Assignment_code.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QoiBrqcJjD3V4emWMgoPYbKJksvjXcGz
"""
#Install and import libraries

! pip3 install accelerate

from google.colab import drive
drive.mount('/content/drive')

!pip install tensorflow
!pip install transformers

pip install tensorflow==2.12.0 tensorflow-probability==0.15.0

pip install datasets

import torch
from transformers import AutoModelForSpeechSeq2Seq, AutoProcessor, pipeline
from datasets import load_dataset

device = "cuda:0" if torch.cuda.is_available() else "cpu"
torch_dtype = torch.float16 if torch.cuda.is_available() else torch.float32

#Load the model

model_id = "openai/whisper-large-v3"

model = AutoModelForSpeechSeq2Seq.from_pretrained(
    model_id, torch_dtype=torch_dtype, use_safetensors=True
)

model.to(device)

processor = AutoProcessor.from_pretrained(model_id)

pipe = pipeline(
    "automatic-speech-recognition",
    model=model,
    tokenizer=processor.tokenizer,
    feature_extractor=processor.feature_extractor,
    max_new_tokens=128,
    chunk_length_s=30,
    batch_size=16,
    return_timestamps=True,
    torch_dtype=torch_dtype,
    device=device,
)

sample = '/content/common_voice_mr_31671592.wav'
result = pipe(sample, generate_kwargs={"language": "marathi"})
print(result["text"])

import os
import gdown

import os

#Function to get transcriptions of audio files
def get_transcription(filename: str):

    file_path = os.path.join(folder_path, filename)

    result = pipe(file_path, generate_kwargs={"language": "marathi"})

    return f"{filename} {result['text']}"

def process_and_save_transcriptions(folder_path: str, batch_size: int, output_file_path: str):
    all_results = []

    audio_files = [filename for filename in os.listdir(folder_path) if filename.endswith('.wav')]

    for i in range(0, min(len(audio_files), batch_size), batch_size):
        batch_files = audio_files[i:i+batch_size]

        for filename in batch_files:
            transcription = get_transcription(filename)

            all_results.append(transcription)

    with open(output_file_path, 'w', encoding='utf-8') as output_file:
        output_file.write('\n'.join(all_results))

    print(f'Processed {len(all_results)} files. Results saved to: {output_file_path}')

folder_path = '/content/drive/MyDrive/common_voice_test'
batch_size = 1816
output_file_path = '/content/drive/MyDrive/common_voice_text_results(8).txt'

process_and_save_transcriptions(folder_path, batch_size, output_file_path)


# Download the file
file_id = '/content/drive/MyDrive'
gdown.download(f'https://drive.google.com/uc?id={file_id}', output_file_path + '_downloaded.txt')

print(f'Text file downloaded to: {output_file_path}_downloaded.txt')

from google.colab import files

uploaded = files.upload()

with open('/content/trans.txt', 'r', encoding='utf-8') as file:
    lines = file.readlines()

sorted_lines = sorted(lines, key=lambda x: int(x.split('_')[-1].split('.')[0]))

with open('sorted_trans(1).txt', 'w', encoding='utf-8') as file:
    file.writelines(sorted_lines)
files.download('sorted_trans(1).txt')

from google.colab import files

uploaded = files.upload()

with open('/content/common_voice_text_results(8).txt', 'r', encoding='utf-8') as file:
    lines = file.readlines()

sorted_lines = sorted(lines, key=lambda x: int(''.join(filter(str.isdigit, x.split('_')[-1].split('.')[0]))))

with open('sorted_common_voice(8).txt', 'w', encoding='utf-8') as file:
    file.writelines(sorted_lines)
files.download('sorted_common_voice(8).txt')

!pip install jiwer

import jiwer
import re

# Function to calculate Word Error Rate between two sentences
def calculate_wer(reference, hypothesis):
    try:
        return jiwer.wer(reference, hypothesis)
    except ValueError as e:
        print(f"Error calculating WER: {e}")
        return None

with open('/content/sorted_trans(1).txt', 'r', encoding='utf-8') as file1:
    trans_lines = file1.readlines()

with open('/content/sorted_common_voice(8).txt', 'r', encoding='utf-8') as file2:
    common_voice_lines = file2.readlines()

if len(trans_lines) != len(common_voice_lines):
    print("Warning: The number of sentences in the two files is different.")

# Calculate WER for each pair of sentences
min_length = min(len(trans_lines), len(common_voice_lines))
wer_results = []
for ref, hyp in zip(trans_lines[:min_length], common_voice_lines[:min_length]):
    reference = re.findall(r'\b\w+\b', ref)
    hypothesis = re.findall(r'\b\w+\b', hyp)

    max_length = max(len(reference), len(hypothesis))
    reference += [''] * (max_length - len(reference))
    hypothesis += [''] * (max_length - len(hypothesis))

    wer = calculate_wer(reference, hypothesis)
    if wer is not None:
        wer_results.append(wer)

with open('wer_results.txt', 'w', encoding='utf-8') as wer_file:
    for wer in wer_results:
        wer_file.write(f'{wer}\n')

from google.colab import files
files.download('wer_results.txt')